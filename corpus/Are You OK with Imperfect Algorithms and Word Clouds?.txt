The glory days of artificial intelligence (AI) have descended upon us as most, if not all, of new technologies/apps purport to leverage AI. The tech promises to “learn” your habits and “adapt” as your habits change. The ease of use and seemingly intuitive operation of technologies/apps ingratiates us into believing that tech is smart and understands our needs. In reality, algorithms are guiding the tech’s decision selections. And who is behind the making and applying of algorithms? That’s right: people.
While you’ve been told repeatedly that people are instrumental in tech, you should know just how integral people who code are in the process. People who code come from a myriad of backgrounds holding job titles like software developer, data analyst, software engineer, data engineer, machine learning engineer and data scientist, to name a few.
I’m going to show you the dumbness of algorithms by executing a series of Python text analysis routines, briefly describing what’s happening at each step and displaying output as word clouds. Word clouds are a powerful visual representation aid that helps us emphasize how unwavering algorithms truly are.
Let’s start with the input: my own Twitter posts. The table below displays the first 5 rows of my Twitter data including the number of likes (favorite_count), number of retweets (retweet_count), timestamp (created_at) and post text (full_text). An actual Twitter post contains many more columns that have been removed for this demonstration.